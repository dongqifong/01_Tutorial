{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alive-breed",
   "metadata": {},
   "source": [
    "# ROC Curve, AUC, PR Curve and F1-Score\n",
    "\n",
    "## Introduction\n",
    "\n",
    "> 在處理分類問題時，最後的輸出往往是樣本被歸在某類的\"機率\"，最後將樣本歸類於機率最大值的類別。\n",
    "\n",
    "但統計有一句很有名的格言\n",
    "\n",
    "> All models are wrong, but some are useful.\n",
    "\n",
    "也就是很難找到一個完美的模型能夠為樣本完美分類，畢竟樣本本身就會有變異數在\n",
    "\n",
    "那麼如何對一個模型\"評分\"呢?又或者有甚麼指標可以參考?\n",
    "\n",
    "底下介紹常見的評估方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-variation",
   "metadata": {},
   "source": [
    "# ROC Curve\n",
    "\n",
    "> ROC的全名叫做Receiver Operating Characteristic，是以偽陽性率(FPR)為橫軸，真陽性率(TPR)為縱軸所繪製的曲線，\n",
    "曲線上的點代表不同閾值(threshold)下，該模型FPR和TPR的對應關係，底下介紹觀念及算法\n",
    "\n",
    "## 混淆矩陣(Confusion Matrix):\n",
    "\n",
    "\n",
    "||實際YES|實際NO|\n",
    "|:---:|:---:|:---:|\n",
    "|預測YES|True Positive(TP)|False Positive(FP)|\n",
    "|預測NO|False Negative(FN)|True Negative(TN)|\n",
    "\n",
    "\n",
    "## 真陽性率(TPR),召回率(Recall),敏感度(Sensitivity):\n",
    "\n",
    "意思:在所有正樣本中，有多少比例預測正確\n",
    "\n",
    "$$TPR=\\frac{TP}{TP+FN}$$\n",
    "\n",
    "\n",
    "## 偽陽性率(TPR):\n",
    "\n",
    "意思:在所有負樣本中，有多少比例被預測為正，也等於1-特異度(Sensitivity)\n",
    "\n",
    "$$FPR=\\frac{FP}{FP+TN}=1-\\frac{TN}{TN + FP}=1-Specificity$$\n",
    "\n",
    "\n",
    "Remark:特異度(Sensitivity)的意思為，在所有負樣本中，預測正確的比例\n",
    "\n",
    "## ROC and AUC\n",
    "\n",
    "ROC:將各個Threshold情況下的FPR和TPR對應關係描繪出來\n",
    "\n",
    "AUC:全名叫做Area Under the Curve(AUC)，就是ROC曲線下的面積，下圖為0.79\n",
    "\n",
    "<img src=\"ROC.PNG\" width=\"40%\" />\n",
    "\n",
    "圖片來源:https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-p\n",
    "\n",
    "## 討論:\n",
    "\n",
    "由圖可發現，當TPR越大，那麼FPT也會越大，這是因為當你\"放寬\"了Threshold時，雖然會讓正樣本預測正確的比例增加，但錯把負樣本分類成正(Positive)的機會也同時增加了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-reconstruction",
   "metadata": {},
   "source": [
    "# PR Curve\n",
    "\n",
    "> 以準確率(Precision)縱軸，召回率(Recall)為橫軸，所繪製的曲線圖\n",
    "\n",
    "## 準確率(Precision)\n",
    "\n",
    "意思:在預測為正的樣本中，確實為正樣本的比例。\n",
    "\n",
    "$$Precision=\\frac{TP}{TP+FP}$$\n",
    "\n",
    "## Precision- Recall Curve\n",
    "<img src=\"PR_Curve.PNG\" width=\"40%\" />\n",
    "\n",
    "圖片來源:https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py\n",
    "\n",
    "\n",
    "Average Precision(AP):\n",
    "\n",
    "不同threshold下，Recall差異比上Precision的平均\n",
    "\n",
    "<img src=\"AP.PNG\" width=\"20%\" />\n",
    "\n",
    "$R_n$=Recall at the nth threshold\n",
    "\n",
    "$P_n$=Precision at the nth threshold\n",
    "\n",
    "圖片來源:https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score\n",
    "\n",
    "## 討論:\n",
    "\n",
    "### Precision vs. Recall\n",
    "\n",
    "Precision探討的範圍是在預測為正樣本的情況下，有多少比例為真的正樣本\n",
    "\n",
    "而Recall探討的是範圍是在真實為正樣本的情況下，有多少比例預測正確\n",
    "\n",
    "所以根據不同目標要關注的指標就會不同\n",
    "\n",
    "### 使用場景\n",
    "\n",
    "在資料不平衡的情況下，例如疫苗的正確率，通常使用ROC，因為ROC會將正樣本和負樣本分開討論，所以比較可以克服正負樣本不平衡的問題\n",
    "\n",
    "在資料平衡的情況下，PR更專注於那些真實為正樣本的分類正確率，比方說信用卡詐欺檢測。\n",
    "\n",
    "一般情況下，調高threshold能提高Precision，但Recall會降低"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-explorer",
   "metadata": {},
   "source": [
    "# F1-Score\n",
    "\n",
    "> 將Precision和Recall做調和平均的指標。\n",
    "\n",
    "由上面討論可發現，不同情況下所關注的指標不同，也可能要同時考慮到兩者，這時候將兩者做調和平均做為新的指標，就是F1-Score。\n",
    "\n",
    "F1-Score是F-measure通式的一個特例\n",
    "\n",
    "## F-Measure\n",
    "\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/136f45612c08805f4254f63d2f2524bc25075fff\" width=\"30%\" />\n",
    "\n",
    "圖片來源:Wiki\n",
    "\n",
    "## F1-Score\n",
    "\n",
    "Let $\\beta=1$\n",
    "\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/4179c69cf1dde8418c4593177521847e862e7df8\" width=\"50%\" />\n",
    "\n",
    "圖片來源:Wiki\n",
    "\n",
    "## 討論:\n",
    "\n",
    "由F-measure的計算式可發現，當$\\beta$趨近於無限大時，F-measure就是Recall；當$\\beta$等於零，則代表了Precision。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
